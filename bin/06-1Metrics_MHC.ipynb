{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['plddts', 'pae', 'pde', 'mean_plddt', 'mean_pae', 'pae_prot', 'pae_inter', 'same_chain'])\n",
      "plddts: tensor([[0.6169, 0.7354, 0.7930, 0.7947, 0.8703, 0.8983, 0.8394, 0.8601, 0.8074,\n",
      "         0.8635, 0.7980, 0.8425, 0.7747, 0.7541, 0.7608, 0.7803, 0.7347, 0.7770,\n",
      "         0.8487, 0.7782, 0.8162, 0.8366, 0.7900, 0.8494, 0.8480, 0.8976, 0.8546,\n",
      "         0.8817, 0.8754, 0.8854, 0.8554, 0.8360, 0.8356, 0.8305, 0.7712, 0.8596,\n",
      "         0.8056, 0.8791, 0.8658, 0.8687, 0.8909, 0.8641, 0.8591, 0.8790, 0.8123,\n",
      "         0.7760, 0.8524, 0.7540, 0.7253, 0.8299, 0.7563, 0.7596, 0.8123, 0.7920,\n",
      "         0.7962, 0.8165, 0.8113, 0.8153, 0.7334, 0.8082, 0.8167, 0.8574, 0.8341,\n",
      "         0.8053, 0.8215, 0.8401, 0.8000, 0.7527, 0.8520, 0.8014, 0.8053, 0.8582,\n",
      "         0.8401, 0.8053, 0.7505, 0.7617, 0.8336, 0.8044, 0.8562, 0.9078, 0.9027,\n",
      "         0.8416, 0.8805, 0.8316, 0.8780, 0.8192, 0.8565, 0.8798, 0.8553, 0.8051,\n",
      "         0.8858, 0.8159, 0.8831, 0.8785, 0.8176, 0.8433, 0.7624, 0.6748, 0.6427,\n",
      "         0.5436, 0.3070, 0.3748, 0.3601, 0.3938, 0.3961, 0.3942, 0.3456, 0.3765,\n",
      "         0.7426, 0.8157, 0.8488, 0.8768, 0.8713, 0.7735, 0.8379, 0.8340, 0.8413,\n",
      "         0.8749, 0.8446, 0.8225, 0.8098, 0.6732, 0.6905, 0.6869, 0.6162, 0.7274,\n",
      "         0.7484, 0.8264, 0.7676, 0.8570, 0.8631, 0.8682, 0.8638, 0.9028, 0.8408,\n",
      "         0.8840, 0.8281, 0.8232, 0.8493, 0.8136, 0.8262, 0.8731, 0.7945, 0.8798,\n",
      "         0.8657, 0.8695, 0.8025, 0.8486, 0.8305, 0.8188, 0.8572, 0.8012, 0.8718,\n",
      "         0.8529, 0.8802, 0.8052, 0.8586, 0.8316, 0.8132, 0.8298, 0.7862, 0.7722,\n",
      "         0.8051, 0.8499, 0.8584, 0.7931, 0.8389, 0.8208, 0.8309, 0.7800, 0.8398,\n",
      "         0.8934, 0.8147, 0.8537, 0.8642, 0.8512, 0.8465, 0.8253, 0.8635, 0.7807,\n",
      "         0.8368, 0.7838, 0.7764, 0.7840, 0.8585, 0.8287, 0.7482, 0.8267, 0.8375,\n",
      "         0.7721, 0.8379, 0.8092, 0.7954, 0.7712, 0.7636, 0.7298, 0.6677, 0.7057,\n",
      "         0.7597, 0.7633, 0.8267, 0.8542, 0.8635, 0.8797, 0.8076, 0.8577, 0.7735,\n",
      "         0.9046, 0.9078, 0.8685, 0.8602, 0.8681, 0.8277, 0.7966, 0.8272, 0.7501,\n",
      "         0.8775, 0.8313, 0.7581, 0.8877, 0.7988, 0.8703, 0.8453, 0.9020, 0.9073,\n",
      "         0.8811, 0.8629, 0.8702, 0.8230, 0.8793, 0.8889, 0.9100, 0.9153, 0.8949,\n",
      "         0.8765, 0.7784, 0.8560, 0.8808, 0.8817, 0.8995, 0.8836, 0.9012, 0.9144,\n",
      "         0.8926, 0.8736, 0.8674, 0.8929, 0.9141, 0.8798, 0.8909, 0.8983, 0.8837,\n",
      "         0.8455, 0.8476, 0.8645, 0.8751, 0.8921, 0.8811, 0.7788, 0.8791, 0.9080,\n",
      "         0.8316, 0.8404, 0.8404, 0.8305, 0.8941, 0.8680, 0.8939, 0.8793, 0.8755,\n",
      "         0.8619, 0.9006, 0.8969, 0.8101, 0.8133, 0.8966, 0.8261, 0.7785, 0.8502,\n",
      "         0.8736, 0.7976, 0.8334, 0.8654, 0.7638, 0.7534, 0.8090, 0.8403, 0.7893,\n",
      "         0.7501, 0.8476, 0.8558, 0.8917, 0.8999, 0.8184, 0.8759, 0.7889, 0.8704,\n",
      "         0.8204, 0.8158, 0.7704, 0.8044, 0.7684, 0.8110, 0.7715, 0.7796, 0.8312,\n",
      "         0.8651, 0.8522, 0.8752, 0.7724, 0.8907, 0.8265, 0.9107, 0.8631, 0.8800,\n",
      "         0.8740, 0.8541, 0.8668, 0.8581, 0.7789, 0.8916, 0.8723, 0.8743, 0.8678,\n",
      "         0.8562, 0.8536, 0.8250, 0.8462, 0.8415, 0.7842, 0.8291, 0.8035, 0.7758,\n",
      "         0.7359, 0.7917, 0.8343, 0.7779, 0.7738, 0.7855, 0.7356, 0.8478, 0.7376,\n",
      "         0.8388, 0.8261, 0.7733, 0.7678, 0.6945, 0.8546, 0.8394, 0.8401, 0.8371,\n",
      "         0.7822, 0.8881, 0.8856, 0.8618, 0.8705, 0.8633, 0.8514, 0.8093, 0.8339,\n",
      "         0.8028, 0.8220, 0.7629, 0.7726, 0.8555, 0.8654, 0.8959, 0.8302, 0.9057,\n",
      "         0.8322, 0.8884, 0.7937, 0.8599, 0.8759, 0.8434, 0.7804, 0.8612, 0.8530,\n",
      "         0.8745, 0.8608, 0.7963, 0.7970, 0.7338, 0.6875]])\n",
      "pae: tensor([[[ 0.2502,  0.9319,  2.4660,  ..., 22.6041, 22.8957, 23.8011],\n",
      "         [ 0.5821,  0.2500,  0.7995,  ..., 17.0612, 17.7417, 18.7053],\n",
      "         [ 1.3945,  0.4781,  0.2500,  ...,  9.5091,  9.5304, 10.1706],\n",
      "         ...,\n",
      "         [10.5156, 10.3972,  9.7196,  ...,  0.2500,  0.4057,  1.5309],\n",
      "         [18.0810, 17.4962, 16.1775,  ...,  0.7010,  0.2500,  0.9672],\n",
      "         [24.5163, 24.7546, 24.5285,  ...,  3.0777,  1.0809,  0.2502]]])\n",
      "pde: tensor([[[0.1500, 0.2186, 0.3944,  ..., 1.8949, 2.0122, 2.5373],\n",
      "         [0.2186, 0.1500, 0.1671,  ..., 1.4924, 1.7022, 2.0242],\n",
      "         [0.3944, 0.1671, 0.1500,  ..., 1.3233, 1.4158, 1.7922],\n",
      "         ...,\n",
      "         [1.8949, 1.4924, 1.3233,  ..., 0.1500, 0.1708, 0.4275],\n",
      "         [2.0122, 1.7022, 1.4158,  ..., 0.1708, 0.1500, 0.2482],\n",
      "         [2.5373, 2.0242, 1.7922,  ..., 0.4275, 0.2482, 0.1500]]])\n",
      "mean_plddt: 0.8190146088600159\n",
      "mean_pae: 6.156867980957031\n",
      "pae_prot: 6.156867980957031\n",
      "pae_inter: nan\n",
      "same_chain: tensor([[[1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 1, 1, 1],\n",
      "         [0, 0, 0,  ..., 1, 1, 1],\n",
      "         [0, 0, 0,  ..., 1, 1, 1]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57026/2674688536.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_Test = torch.load(dir_for_model_pt, map_location='cpu')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "dir_for_model_pt = \"./outputs/MHC/MHC_protein_8ROO/MHC_protein_8ROO_aux.pt\"\n",
    "data_Test = torch.load(dir_for_model_pt, map_location='cpu')\n",
    "print(data_Test.keys())\n",
    "\n",
    "## Metrics\n",
    "output_file = \"./outputs/MHC/MHC_protein_8ROO/metrics_RFAA_MHC_8ROO.txt\"\n",
    "with open(output_file, 'w') as f:\n",
    "    for key, value in data_Test.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "        f.write(f\"{key}: {value}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
