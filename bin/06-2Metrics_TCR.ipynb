{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['plddts', 'pae', 'pde', 'mean_plddt', 'mean_pae', 'pae_prot', 'pae_inter', 'same_chain'])\n",
      "mean_plddt: 0.6991813778877258\n",
      "plddts: tensor([[0.1659, 0.2199, 0.2292, 0.2354, 0.2302, 0.2370, 0.2206, 0.2139, 0.1560,\n",
      "         0.3588, 0.4450, 0.5167, 0.6210, 0.7600, 0.7648, 0.7524, 0.6943, 0.7631,\n",
      "         0.7504, 0.7393, 0.7549, 0.7188, 0.7622, 0.7557, 0.7210, 0.7784, 0.7282,\n",
      "         0.7729, 0.7803, 0.8304, 0.8286, 0.8122, 0.8289, 0.7988, 0.6879, 0.6536,\n",
      "         0.5481, 0.5219, 0.5226, 0.5934, 0.5469, 0.6605, 0.7497, 0.7526, 0.8082,\n",
      "         0.7887, 0.7795, 0.7721, 0.7284, 0.6419, 0.6023, 0.6346, 0.7184, 0.7471,\n",
      "         0.7632, 0.7645, 0.7757, 0.7709, 0.7435, 0.7555, 0.6355, 0.6305, 0.5916,\n",
      "         0.6465, 0.6447, 0.7553, 0.7320, 0.7785, 0.7556, 0.7746, 0.7399, 0.8187,\n",
      "         0.8041, 0.8472, 0.8223, 0.7766, 0.7629, 0.6472, 0.6894, 0.7502, 0.7632,\n",
      "         0.7030, 0.8295, 0.8418, 0.8718, 0.7654, 0.8567, 0.8382, 0.8001, 0.8016,\n",
      "         0.7230, 0.7178, 0.7387, 0.7904, 0.7620, 0.7976, 0.7977, 0.8285, 0.8157,\n",
      "         0.8384, 0.8088, 0.7495, 0.6263, 0.5392, 0.4951, 0.5043, 0.4703, 0.5471,\n",
      "         0.6548, 0.7036, 0.7223, 0.7957, 0.7706, 0.8001, 0.8120, 0.6405, 0.7933,\n",
      "         0.6766, 0.7511, 0.6355, 0.6486, 0.5980, 0.6180, 0.5495, 0.5435, 0.6265,\n",
      "         0.5884, 0.6564, 0.7077, 0.7132, 0.7122, 0.7138, 0.7504, 0.6324, 0.6669,\n",
      "         0.6449, 0.6034, 0.6159, 0.5952, 0.5862, 0.6209, 0.7330, 0.7493, 0.7603,\n",
      "         0.7572, 0.6814, 0.7163, 0.6503, 0.6171, 0.5822, 0.5548, 0.5123, 0.5371,\n",
      "         0.5020, 0.5434, 0.4968, 0.4554, 0.4675, 0.4320, 0.4797, 0.5197, 0.5818,\n",
      "         0.6576, 0.6105, 0.6684, 0.6760, 0.6010, 0.6138, 0.6756, 0.6436, 0.6297,\n",
      "         0.5794, 0.5555, 0.5057, 0.5396, 0.5132, 0.5452, 0.5456, 0.6315, 0.6929,\n",
      "         0.6670, 0.7366, 0.7342, 0.7429, 0.7455, 0.6311, 0.6910, 0.5811, 0.5920,\n",
      "         0.5810, 0.5794, 0.6191, 0.6432, 0.6639, 0.5847, 0.5526, 0.5547, 0.4513,\n",
      "         0.4381, 0.3946, 0.3679, 0.3230, 0.3243, 0.3111, 0.2722, 0.2958, 0.2467,\n",
      "         0.5775, 0.6752, 0.7272, 0.7925, 0.7835, 0.7372, 0.7806, 0.7770, 0.7657,\n",
      "         0.8073, 0.7725, 0.7460, 0.7277, 0.6015, 0.5960, 0.5872, 0.5046, 0.6138,\n",
      "         0.6168, 0.7217, 0.7036, 0.7611, 0.8049, 0.8411, 0.8358, 0.8529, 0.7970,\n",
      "         0.8055, 0.7598, 0.6988, 0.7621, 0.7571, 0.7731, 0.8309, 0.7768, 0.8192,\n",
      "         0.8122, 0.7915, 0.7344, 0.7713, 0.7139, 0.7291, 0.7355, 0.7251, 0.7832,\n",
      "         0.7918, 0.8136, 0.7472, 0.7968, 0.7416, 0.7400, 0.7516, 0.7157, 0.6469,\n",
      "         0.7116, 0.6839, 0.7091, 0.6312, 0.7281, 0.7571, 0.7347, 0.6672, 0.7642,\n",
      "         0.7986, 0.6923, 0.7338, 0.7833, 0.7274, 0.7215, 0.6915, 0.7729, 0.6560,\n",
      "         0.6948, 0.7444, 0.6552, 0.6807, 0.7214, 0.7283, 0.7018, 0.6687, 0.7082,\n",
      "         0.6496, 0.6497, 0.6152, 0.6441, 0.6085, 0.6600, 0.6212, 0.6007, 0.5795,\n",
      "         0.6388, 0.6865, 0.7338, 0.7747, 0.7571, 0.7981, 0.7743, 0.7832, 0.7113,\n",
      "         0.7964, 0.8029, 0.7617, 0.7190, 0.6577, 0.6294, 0.5769, 0.6327, 0.5806,\n",
      "         0.7359, 0.6950, 0.6978, 0.7824, 0.7357, 0.7310, 0.7727, 0.7792, 0.7976,\n",
      "         0.7560, 0.7232, 0.7422, 0.6776, 0.7374, 0.7602, 0.7767, 0.8090, 0.7979,\n",
      "         0.7427, 0.6827, 0.6813, 0.7687, 0.6634, 0.7487, 0.7679, 0.7447, 0.7561,\n",
      "         0.6775, 0.6810, 0.6347, 0.7043, 0.7704, 0.7086, 0.6835, 0.7576, 0.7616,\n",
      "         0.6426, 0.6308, 0.7349, 0.7064, 0.6532, 0.6419, 0.6301, 0.7284, 0.7714,\n",
      "         0.6445, 0.6456, 0.7203, 0.6939, 0.6756, 0.6963, 0.7648, 0.6802, 0.7044,\n",
      "         0.6104, 0.7777, 0.7512, 0.6477, 0.7039, 0.7888, 0.7011, 0.6553, 0.7538,\n",
      "         0.7617, 0.6692, 0.7065, 0.7359, 0.6437, 0.6317, 0.7075, 0.7601, 0.7143,\n",
      "         0.6689, 0.7578, 0.7702, 0.7999, 0.8183, 0.7140, 0.7791, 0.7173, 0.7636,\n",
      "         0.7654, 0.7320, 0.6943, 0.7312, 0.6637, 0.6751, 0.6758, 0.6662, 0.7153,\n",
      "         0.7807, 0.7712, 0.8031, 0.7508, 0.8378, 0.7771, 0.8528, 0.8071, 0.8105,\n",
      "         0.7959, 0.7671, 0.7820, 0.7966, 0.6972, 0.8068, 0.7918, 0.8089, 0.7894,\n",
      "         0.7832, 0.7635, 0.7183, 0.6777, 0.7007, 0.6819, 0.6996, 0.6689, 0.6233,\n",
      "         0.5768, 0.6080, 0.7041, 0.6637, 0.7105, 0.7064, 0.6383, 0.7749, 0.6625,\n",
      "         0.7543, 0.7576, 0.7072, 0.6977, 0.7485, 0.7781, 0.7803, 0.8008, 0.7883,\n",
      "         0.7344, 0.8235, 0.8222, 0.7943, 0.7530, 0.7661, 0.7450, 0.7289, 0.7519,\n",
      "         0.7187, 0.7534, 0.7003, 0.7111, 0.7791, 0.7933, 0.8358, 0.7713, 0.8302,\n",
      "         0.7479, 0.8053, 0.7101, 0.7787, 0.7766, 0.7276, 0.6908, 0.7615, 0.7663,\n",
      "         0.7742, 0.7791, 0.7093, 0.7203, 0.6469, 0.5889, 0.2907, 0.3772, 0.4960,\n",
      "         0.6178, 0.7505, 0.7518, 0.7762, 0.7478, 0.7974, 0.7246, 0.7676, 0.7305,\n",
      "         0.8062, 0.7938, 0.7319, 0.7606, 0.7887, 0.7413, 0.7632, 0.7649, 0.8026,\n",
      "         0.8061, 0.7441, 0.8123, 0.7586, 0.6695, 0.5667, 0.4855, 0.4937, 0.5829,\n",
      "         0.5728, 0.6289, 0.7242, 0.7356, 0.7738, 0.7633, 0.7583, 0.7743, 0.7373,\n",
      "         0.6633, 0.6196, 0.6302, 0.7119, 0.7462, 0.7004, 0.7268, 0.7389, 0.6580,\n",
      "         0.6090, 0.6910, 0.5945, 0.5648, 0.5152, 0.4566, 0.4106, 0.4534, 0.4407,\n",
      "         0.4344, 0.5309, 0.4561, 0.5131, 0.5683, 0.5815, 0.6879, 0.6495, 0.6709,\n",
      "         0.7015, 0.6770, 0.5825, 0.6098, 0.6170, 0.5829, 0.6453, 0.7221, 0.7168,\n",
      "         0.7951, 0.8049, 0.6986, 0.7639, 0.6868, 0.7312, 0.7642, 0.7802, 0.7565,\n",
      "         0.7435, 0.7522, 0.7767, 0.7897, 0.8133, 0.8181, 0.7907, 0.8254, 0.8016,\n",
      "         0.7601, 0.6806, 0.5569, 0.5094, 0.4947, 0.4972, 0.4881, 0.4696, 0.4530,\n",
      "         0.5460, 0.6117, 0.7128, 0.7304, 0.7914, 0.7586, 0.8067, 0.8237, 0.7228,\n",
      "         0.8105, 0.8102, 0.8064, 0.7759, 0.7136, 0.7089, 0.7543, 0.7155, 0.7301,\n",
      "         0.8112, 0.7387, 0.8187, 0.8363, 0.7326, 0.8107, 0.8244, 0.8239, 0.8008,\n",
      "         0.7921, 0.8221, 0.7663, 0.6944, 0.7426, 0.7502, 0.7708, 0.7357, 0.6254,\n",
      "         0.6978, 0.6699, 0.7072, 0.8378, 0.8335, 0.8539, 0.8573, 0.8718, 0.8183,\n",
      "         0.8628, 0.7932, 0.7990, 0.8028, 0.7887, 0.8106, 0.7836, 0.7873, 0.8316,\n",
      "         0.7709, 0.8178, 0.8507, 0.8569, 0.8036, 0.8452, 0.8281, 0.8413, 0.7521,\n",
      "         0.7876, 0.7852, 0.7152, 0.7511, 0.7941, 0.8101, 0.7722, 0.7828, 0.7503,\n",
      "         0.6739, 0.6402, 0.7529, 0.6762, 0.6209, 0.5543, 0.4719, 0.4271, 0.4189,\n",
      "         0.4174, 0.4600, 0.5368, 0.6093, 0.6726, 0.7543, 0.7953, 0.7959, 0.8112,\n",
      "         0.8540, 0.7395, 0.8604, 0.7298, 0.8331, 0.8056, 0.8161, 0.7840, 0.7706,\n",
      "         0.8092, 0.7937, 0.8290, 0.8141, 0.7360, 0.8451, 0.8329, 0.8353, 0.8036,\n",
      "         0.8799, 0.7924, 0.8657, 0.7933, 0.8314, 0.7666, 0.7933, 0.7542, 0.7379,\n",
      "         0.6786, 0.6792, 0.7056, 0.6275, 0.6885, 0.6570, 0.6464, 0.6399, 0.6268,\n",
      "         0.7373, 0.7497, 0.7815, 0.7548, 0.7745, 0.7640, 0.8122, 0.8141, 0.8353,\n",
      "         0.8594, 0.8085, 0.8473, 0.7910, 0.8022, 0.6475, 0.6506, 0.5632]])\n",
      "pae: tensor([[[ 0.5132,  3.3976,  4.6978,  ..., 30.7709, 30.7980, 30.8882],\n",
      "         [ 3.5066,  0.3539,  2.8583,  ..., 30.6327, 30.7730, 30.6326],\n",
      "         [ 4.6978,  3.3668,  0.2957,  ..., 30.5921, 30.6909, 30.5279],\n",
      "         ...,\n",
      "         [28.7718, 29.3571, 29.1288,  ...,  0.2500,  1.4028,  2.8712],\n",
      "         [29.2579, 29.6709, 29.5533,  ...,  1.3533,  0.2506,  1.6187],\n",
      "         [28.7618, 29.6505, 29.4854,  ...,  2.9684,  1.7807,  0.2539]]])\n",
      "pde: tensor([[[ 0.1597,  1.7365,  1.4107,  ..., 13.1312, 12.4934, 13.4396],\n",
      "         [ 1.7365,  0.1512,  1.2622,  ..., 13.0209, 12.9206, 12.0765],\n",
      "         [ 1.4107,  1.2622,  0.1508,  ..., 12.6158, 12.5697, 11.7606],\n",
      "         ...,\n",
      "         [13.1312, 13.0209, 12.6158,  ...,  0.1500,  0.2940,  0.6281],\n",
      "         [12.4934, 12.9206, 12.5697,  ...,  0.2940,  0.1500,  0.4268],\n",
      "         [13.4396, 12.0765, 11.7606,  ...,  0.6281,  0.4268,  0.1500]]])\n",
      "mean_plddt: 0.6991813778877258\n",
      "mean_pae: 18.4393310546875\n",
      "pae_prot: 18.4393310546875\n",
      "pae_inter: nan\n",
      "same_chain: tensor([[[1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 1, 1, 1],\n",
      "         [0, 0, 0,  ..., 1, 1, 1],\n",
      "         [0, 0, 0,  ..., 1, 1, 1]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5002/2423469714.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_Test = torch.load(dir_for_model_pt, map_location='cpu')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "dir_for_model_pt = \"./outputs/TCR/TCR_protein_8RYN/TCR_protein_8RYN_aux.pt\"\n",
    "data_Test = torch.load(dir_for_model_pt, map_location='cpu')\n",
    "print(data_Test.keys())\n",
    "\n",
    "## Metrics\n",
    "output_file = \"./outputs/TCR/TCR_protein_8RYN/metrics_RFAA_8RYN.txt\"\n",
    "mean_plddt = data_Test.get('mean_plddt')\n",
    "print(f\"mean_plddt: {mean_plddt}\")\n",
    "with open(output_file, 'w') as f:\n",
    "    for key, value in data_Test.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "        f.write(f\"{key}: {value}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
